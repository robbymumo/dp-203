{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "synapsez5na780"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline 1')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "transformed_data",
						"type": "SynapseNotebook",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebook": {
								"referenceName": "transformed_data",
								"type": "NotebookReference"
							},
							"snapshot": true
						}
					}
				],
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/notebooks/transformed_data')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/transformed_data')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "sparkz5na780",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "aca7d5f9-02f4-4979-af26-abfa0eaf71da"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/58f23e2f-b55c-4733-ab1f-17fc44624e2d/resourceGroups/dp203-z5na780/providers/Microsoft.Synapse/workspaces/synapsez5na780/bigDataPools/sparkz5na780",
						"name": "sparkz5na780",
						"type": "Spark",
						"endpoint": "https://synapsez5na780.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sparkz5na780",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Import necessary libraries\r\n",
							"from pyspark.sql import SparkSession\r\n",
							"from pyspark.sql.functions import *"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df = spark.read.load('abfss://files@datalakez5na780.dfs.core.windows.net/sales_data/Sales Data.csv', format='csv',\r\n",
							"## If header exists uncomment line below\r\n",
							"header=True\r\n",
							")\r\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import col, year, to_date\r\n",
							"\r\n",
							"# Convert Order Date to a date type, handling different formats and cleaning invalid dates\r\n",
							"df = df.withColumn('Order Date', to_date(col('Order Date'), 'MM/dd/yyyy'))\r\n",
							"\r\n",
							"# Filter out rows where Order Date could not be parsed (i.e., null values after conversion)\r\n",
							"df = df.filter(col('Order Date').isNotNull())\r\n",
							""
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Convert OrderDate to a date type and add a new Year column\r\n",
							"# df = df.withColumn('OrderDate', to_date(col('OrderDate'), 'MM/dd/yyyy'))  # Adjust date format as needed\r\n",
							"df = df.withColumn('Year', year(col('Order Date')))\r\n",
							"\r\n",
							"# Save the DataFrame as a Parquet file back to Azure Data Lake Storage\r\n",
							"df.write.mode('overwrite').parquet('abfss://files@datalakez5na780.dfs.core.windows.net/sales_data/Sales_Data_with_Year.parquet')\r\n",
							"\r\n",
							"print(\"DataFrame has been saved as a Parquet file with the new 'Year' column.\")"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		}
	]
}